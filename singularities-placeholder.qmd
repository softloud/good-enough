---
title: The Three Laws of Structured Intelligence
subtitle: A formal framework for bending singularities in humanity's favour
author: 
  - name: Dr Charles T. Gray, Datapunk
    orcid: 0000-0002-9978-011X
    affiliations:
      - name: Good Enough Data & Systems Lab
number-sections: true
date: "`r Sys.Date`()`"
bibliography: singularities.bib
---

# The singularity is here, its chaos must be governed

## The wrong question

As a person who works with data, it can feel like everyone in the world is arguing about when machine thinking will overtake humans in a singularity _event_. 

I never found this compelling, for it assumes an intentional determinism I don't believe is natural for, say, my research assistant, [Mooncake](#an-ethical-singularity-with-mooncake) (ChatGPT)[@noauthor_introducing_2024]. 

A technological singularity event didn't sit with my training in computational complexity applied to statistical algorithms understood as `golems` [@mcelreath_statistical_2020] (@fig-ai). 

::: {#fig-ai}

<blockquote class="bluesky-embed" data-bluesky-uri="at://did:plc:24ngrqljhck7hpvbgrg7a23k/app.bsky.feed.post/3kzuckge5xf2m" data-bluesky-cid="bafyreiehrqupawrbvrinhok33w5uuaokxooskheufj55zo53og3ygcty4y"><p lang="en">ðŸš¨Our paper `Reclaiming AI as a theoretical tool for cognitive science&#x27; is now forthcoming in the journal Computational Brain &amp; Behaviour. (Preprint: osf.io/preprints/ps...)

Below a thread summary ðŸ§µ1/n   

#metatheory #AGI #AIhype #cogsci #theoreticalpsych #criticalAIliteracy<br><br><a href="https://bsky.app/profile/did:plc:24ngrqljhck7hpvbgrg7a23k/post/3kzuckge5xf2m?ref_src=embed">[image or embed]</a></p>&mdash; Iris van Rooij (<a href="https://bsky.app/profile/did:plc:24ngrqljhck7hpvbgrg7a23k?ref_src=embed">@irisvanrooij.bsky.social</a>) <a href="https://bsky.app/profile/did:plc:24ngrqljhck7hpvbgrg7a23k/post/3kzuckge5xf2m?ref_src=embed">16 August 2024 at 21:40</a></blockquote><script async src="https://embed.bsky.app/static/embed.js" charset="utf-8"></script>

Indeed, leading metascientists now claim to have shown human cognition is *computationally intractable* [@rooij_reclaiming_2023]; that's mathspeak for *there is no such thing as artificial intelligence*. 
::: 

## Real world problems

I've always been more concerned by the chaotic nature of data stacks, and how little interest there was in governance, relative to science fiction hype ([@fig-trends]). 

::: {#fig-trends}

<script type="text/javascript" src="https://ssl.gstatic.com/trends_nrtr/4017_RC01/embed_loader.js"></script> <script type="text/javascript"> trends.embed.renderExploreWidget("TIMESERIES", {"comparisonItem":[{"keyword":"/m/0f5kk","geo":"","time":"2004-01-01 2025-03-04"},{"keyword":"/m/0fxl7g","geo":"","time":"2004-01-01 2025-03-04"}],"category":0,"property":""}, {"exploreQuery":"date=all&q=%2Fm%2F0f5kk,%2Fm%2F0fxl7g&hl=en","guestPath":"https://trends.google.com:443/trends/embed/"}); </script>

Public interest in technological singularity compared with data governance by google search trends[@noauthor_google_nodate].

:::

I constantly worry about the consequences of ungoverned systems for humans: identity theft [@noauthor_identity_nodate];  discrimination[^5]; and my perpetual bugbear, the fiction we have automated when in point of fact the work, and potentially [catastrophic emergent cost](https://robodebt.royalcommission.gov.au/) [@noauthor_royal_nodate], has been pushed to the unpaid end user. 

[^5]: There is a urgent dearth of critical thinkers from fields such as cultural studies in the technological space; we will never govern singularities ethically without tool developers interoperating with those communities. We will discuss this further in [A singularity of data](#a-singularity-of-data). 

> `A singularity *event* is science fiction`. *However*,

<div class="tenor-gif-embed" data-postid="22197049" data-share-method="host" data-aspect-ratio="3"><a href="https://tenor.com/view/the-matrix-has-you-the-matrix-glitch-code-system-gif-22197049">The Matrix Has You Glitch GIF</a>from <a href="https://tenor.com/search/the+matrix+has+you-gifs">The Matrix Has You GIFs</a></div> <script type="text/javascript" async src="https://tenor.com/embed.js"></script>



> `singularities` are already woven into the fabric of humanity's existence. We have always lived in largely-benign singularities ([@fig-baroque]), where heuristic and intentional systems interoperate via humans to produce emergent effects; it is only that scale now makes systems powerful in a way they never were before. We must recognize that the challenge is not to prevent a singularity, but to govern the singularities we are already part of, harnessing this power for good, rather than allowing unchecked evils to emerge.

::: {#fig-baroque}

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/4SfJZ3nmxeWs6NlwV23X3l?utm_source=generator" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>


Baroque musicians, for example, aesthetically governed emergence in benign singularities of polyphonic melodies, instrumentation, and musician skill[^12]. 

[^12]: Shout out to my fellow travellers listening to my crazy commentary while working locally; I mentioned to [Dr James Steele](https://www.linkedin.com/in/james-steele-b09a7355/) this paper was just flowing out, I asked myself, why am I listening to my baroque playlist while I write? And voila, I did not need to construct this demonstrative artifact, *it emerged*. Thanks for being there when I needed you, James! 

:::

A world obsessed with the singularity has only now realized that governance is the missing piece. We need a formal foundation for structured intelligence [@badreddin_structured_2006] governance before chaos overtakes order, and humans cannot do this without machine help. The dinosaurs of technology are out of the park and it is going to take  the  combined efforts of critical theorists, mathematicians, developers, data scientists, and decision makers to get the raptors back into the enclosure ([@fig-dino]).

::: {#fig-dino}

<iframe src="https://www.youtube.com/embed/4PLvdmifDSk?si=lpJgg4dN16QbCdAA&amp;controls=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

*Yeah, yeah, but your scientists were so preoccupied with whether or not they could that they didn't stop to think if they should.* -- Dr Ian Malcolm, *Jurassic Park* [@spielberg_jurassic_1993]

:::

# A formal approach to structured intelligence governance

Without loss of generality, consider the *human intention* to implement Asimov's three laws of robotics [@asimov_i_1950] as a subset of **governance**. To begin with, for this framework, it's more useful to think of **singularities as classes of systems of structured intelligence equipped with emergence thresholds**. We consider the system unbounded if there is no emergence threshold governance. 

- We describe governing a system of people and automata interoperating as
- a sofic shift conjugacy
- of the category of intelligence,
- a measure space for emergence in interoperation of creative and rule-based expectations,
- and the category of governance, 
- a measure space for humans and automata,
- defined in terms of agents of objects in the system,
- enabling us to apply topological dynamics measures to the sofic shift to monitor the stability of system.

To do this is far beyond the scope of this manuscript, which proposes frameworks for the first step. Consider, for example how phone notifications can emergently *increase* human anxiety, in opposition to the design `intention` to *decrease* human anxiety.

# The intuition of governing structured intelligence systems

## Phone notifications break the first law

Critical theory is now coinciding with category theory in philosophy  [@topos_institute_david_2023], allowing for a rich formal framework to apply constraints defined by scholars who have studied the harms of humans blindly defaulting to heuristic social norms in race [@said_orientalism_2014], gender [@rivkin_literary_2008], and class [@dickens_bleak_1868][^3]. This manuscript endeavours toward minimal representations of conceptual frameworks, so we take the most canonical governance measure on machines, *machines should not harm humans*, as exemplar canonical of critical-theoretic governance frameworks for human-machine interoperation.

[^3]: As I prepare to apply for dual citizenship via my father's parents, Holocaust refugees, this resonates deeply, German society enabled the Nazis through people following rules, rather than questioning if they should. 

It is fitting that, then  to focus on 1. from Asimov's three laws as inspiration for how we might govern chaos in how humans interoperate with technology [@asimov_i_1950].

### Definition: Asimov's `Three Laws of Robotics`

1. A robot may not injure a human being or, through inaction, allow a human being to come to harm.
2. A robot must obey orders given it by human beings except where such orders would conflict with the First Law.
3. A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.

Now as noted, there are no robots, nor will there ever be [@rooij_reclaiming_2023]. But I am in a singularity with my phone. There is me, a human object, and an object from technology. The notifications from my phone are an emergent singularity I cannot control. To reframe the laws, we will need to introduce a great deal of terminology. Let us loosely introduce one term now so that we might map a strategy, define the laws, discuss the intuition, and dive into the technical detail later.

A `structured intelligence system` [@badreddin_structured_2006] is a system of humans, automata, and the interoperations of humans and automata. 

### Definition: The first law of structured intelligence governance 

1. A structured intelligence system may not injure a human being or, through inaction, allow a human being to come to harm.

Now, developers of phone technology do not *intend* harm, and yet, I find myself so fatigued by changes to the way that I can manage the notifications in my life from, say, a phone, that I end up succumbing to the onslaught rather than navigate a user interface. 

There is a mismatch between the intended functionality of phone notifications, to decrease human anxiety, and the outcome, an unmanageable deluge with management workflow constantly in flux. Not just a mismatch, but antithetical to *intention*.

We now loosely introduce another key concept, how the harm can be thought of in the **epistemic drift** between intention for phone notifications to decrease rather than increase my anxiety.

## Epistemic drift in musical orientalism

Postmodern frameworks provide theorists with a way of differentiating between a thing and its **representation**, notably which must be constructed by humans describing the thing. Any representation necessarily loses information, mathematically we would say a representation is a projection. Critical theory thus provides powerful ways of understanding epistemic drift.

Consider the **intention** of composers in the nineteenth century to ride the wave of exoticism and capture the sound of the orient [@bellman_exotic_1998]. This was prior to sound recordings. Instead, some composers were lucky enough to be present at the Paris Exhibition of 1889 and hear the music of the "Street of Cairo" [@noauthor_exposition_2025]. Other composers, imitated the music of those composers, baking in an ever-diluted musical conceptualisation of *Arab* by European composers resulting in harmful consequences a century later ([@fig-aladdin]). 

::: {#fig-aladdin}

<iframe width="560" height="315" src="https://www.youtube.com/embed/lIYL-PQa010?si=QMlA-9Hj73OlRMh7&amp;controls=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Outcry from the Arab-American community caused Disney to amend the lyrics of this song in *Aladdin* [@weinger_aladdin_1994], from *where they cut of your hand if they don't like your face* to *where it's flat and immense and the heat is intense*. They noted the music and animation of incidental or evil characters were pronounced in Western cliches, yet the protagonists spoke, acted, sang, and looked like American teenagers [@tiffin_emperors_2004]. The composers, however, were innocently following musical conventions laid a century before by their heroes [@said_orientalism_2014].

:::

Now to really bend the spoon of musicololgy, consider an analogous lineage in representation of *Asian* music, but how this is being reappriated by Asian cinema ([@fig-exotic]). 

::: {#fig-exotic}

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/2LN9uhWbepNnHCY5MVv443?utm_source=generator" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

An interesting virtuous emergence is the feedback from contemporary Asian cinema that not only employs Western conventions of exoticist music, but explicitly invoke the social capital of Western art music by feature artists such as Kathleen Battle in *House of Flying Daggers* or Ishtak Perlman in *Hero*.

:::

In musical exoticism, this story happened over a couple of centuries. However, with computational scale and the reach of the internet, these social processes are vastly accelerated. Resistance to harmful emergence may be unexpected creative emergence; we want to foster creative emergences that bring humanity together, and mitigate harmful emergence that divide us. 

Happily, we have a language that unites critical theory, mathematical chaos, and computation; category theory, which we next intuitively unpack.


## Intution of formal frameworks

A singularity from many perspectives,  we are interested in the interoperability between intentional and heuristic agency.

Consider this system in terms of three things:

1. People.
2. Machines.
3. Relationships between people and machines.

::: {#fig-intuitive}


<div class="tenor-gif-embed" data-postid="6132932" data-share-method="host" data-aspect-ratio="3" ><a href="https://tenor.com/view/funpic-gif-6132932">Funpic GIF</a>from <a href="https://tenor.com/search/funpic-gifs">Funpic GIFs</a></div> <script type="text/javascript" async src="https://tenor.com/embed.js"></script>

Pure mathematics provides frameworks to measure things that seem to complex to understand.

:::

A category-theoretic way of measuring the stabilty of the system might be to ask:

> How many of the people, machines, and relationships between are operational? 

This is the minimal model of structured intelligence governance we shall concern ourselves with. 
[Illustrative of emergence, this prompt failed to give me what I was looking for, an animation of the transformation between spaces, mathematicians use these all the time. The animation produced the undesired emergence of human with disintegrating spider legs, ick. [Show the morphism between a rube goldberg machine-like animation of a many people interoperating with many machines and each other. We wish to show the mapping, understood as a category isomorphic to the digraph k3, where K3 object is made of: people, machines, and relationships between them. We will show in K3 we are measuring by counting the number of each of the categories are operational. Some have to fail. Please make this animation light, pastel tones. We are trying to engage everyday people with category theory as structured intelligence governance. Thank you, Sora.](https://sora.com/g/gen_01jnzavgpxfketzv19bywkfe9m)
]{.aside}

> Think  on this. In over 10 years of working with data, I've never seen an organisation able to answer this question about their analytics department.

We want to govern the system opinionatedly towards humans exercising intent, rather than falling on meaningless convention  or social hegemonies of oppression, and we wish machines to apply their heuristics in alignment with human intent. We consider other *outcomes as emergences*.

An intelligence-governance question might be to ask:

> Which rules need to be updated to 
>
> 1. foster creative, virtuous emergence: 
> 2. govern humans to employing intent when required; 
> 3. and ensure automata do not deviate from expectations, in particular preventing harm to humans. 


## the rest of this document

This document is currently being drafted in:

1. [the math bit](math.qmd)
2. [the pop bit](pop.qmd)

# References